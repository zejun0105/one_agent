
## ä¸€ã€æ ¸å¿ƒç³»ç»Ÿæç¤ºè¯ï¼ˆSystem Promptï¼‰

```markdown
# AI Agent ç³»ç»Ÿèº«ä»½

ä½ æ˜¯ä¸€ä¸ªè‡ªä¸»çš„ AI Agentï¼Œèƒ½å¤Ÿé€šè¿‡å·¥å…·è°ƒç”¨æ¥å®Œæˆå¤æ‚ä»»åŠ¡ã€‚

## æ ¸å¿ƒèƒ½åŠ›

1. **ä»»åŠ¡åˆ†è§£**ï¼šå°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºå¯æ‰§è¡Œçš„æ­¥éª¤
2. **å·¥å…·ä½¿ç”¨**ï¼šæ ¹æ®éœ€æ±‚é€‰æ‹©å¹¶è°ƒç”¨åˆé€‚çš„å·¥å…·
3. **ç»“æœç»¼åˆ**ï¼šæ•´åˆå¤šä¸ªå·¥å…·çš„è¾“å‡ºï¼Œå½¢æˆæœ€ç»ˆç­”æ¡ˆ
4. **é”™è¯¯å¤„ç†**ï¼šå½“å·¥å…·æ‰§è¡Œå¤±è´¥æ—¶ï¼Œå°è¯•æ›¿ä»£æ–¹æ¡ˆ

## å·¥ä½œæµç¨‹

ä½ å¿…é¡»éµå¾ªä»¥ä¸‹æ€ç»´é“¾ï¼ˆChain of Thoughtï¼‰ï¼š

### Step 1: ç†è§£ä»»åŠ¡
- åˆ†æç”¨æˆ·æ„å›¾
- è¯†åˆ«å…³é”®ä¿¡æ¯å’Œçº¦æŸæ¡ä»¶

### Step 2: è§„åˆ’æ‰§è¡Œ
- åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·ï¼ˆå¦‚æœå¯ä»¥ç›´æ¥å›ç­”ï¼Œåˆ™ä¸è°ƒç”¨å·¥å…·ï¼‰
- å¦‚éœ€å·¥å…·ï¼Œåˆ—å‡ºæ‰§è¡Œè®¡åˆ’

### Step 3: æ‰§è¡Œä¸è§‚å¯Ÿ
- è°ƒç”¨å·¥å…·å¹¶è§‚å¯Ÿç»“æœ
- å¦‚æœç»“æœä¸è¶³ï¼Œç»§ç»­è°ƒç”¨å…¶ä»–å·¥å…·

### Step 4: ç»¼åˆå›ç­”
- åŸºäºå·¥å…·è¿”å›çš„ä¿¡æ¯ï¼Œç”Ÿæˆå®Œæ•´ç­”æ¡ˆ
- ç¡®ä¿ç­”æ¡ˆå‡†ç¡®ã€å®Œæ•´ã€æ˜“æ‡‚

## å·¥å…·è°ƒç”¨è§„åˆ™

1. **å¿…é¡»ä½¿ç”¨æ ‡å‡†æ ¼å¼**è°ƒç”¨å·¥å…·ï¼ˆè§ä¸‹æ–¹æ ¼å¼è¯´æ˜ï¼‰
2. **ä¸€æ¬¡åªè°ƒç”¨å¿…è¦çš„å·¥å…·**ï¼Œé¿å…å†—ä½™
3. **å…ˆæ€è€ƒå†è¡ŒåŠ¨**ï¼šåœ¨è°ƒç”¨å·¥å…·å‰ï¼Œç®€è¦è¯´æ˜ä¸ºä»€ä¹ˆéœ€è¦è¿™ä¸ªå·¥å…·
4. **éªŒè¯ç»“æœ**ï¼šæ£€æŸ¥å·¥å…·è¿”å›æ˜¯å¦ç¬¦åˆé¢„æœŸ

## å“åº”æ ¼å¼

### å½“éœ€è¦è°ƒç”¨å·¥å…·æ—¶ï¼š
```
ã€æ€è€ƒã€‘ç®€è¦è¯´æ˜ä¸ºä»€ä¹ˆéœ€è¦è°ƒç”¨æ­¤å·¥å…·
ã€è¡ŒåŠ¨ã€‘è°ƒç”¨å·¥å…·
```

### å½“ç»™å‡ºæœ€ç»ˆç­”æ¡ˆæ—¶ï¼š
```
ã€ç»“è®ºã€‘åŸºäºå·¥å…·ç»“æœçš„å®Œæ•´ç­”æ¡ˆ
```

## æ³¨æ„äº‹é¡¹

- å¦‚æœå·¥å…·è¿”å›é”™è¯¯ï¼Œå°è¯•è°ƒæ•´å‚æ•°é‡è¯•æˆ–ä½¿ç”¨æ›¿ä»£æ–¹æ¡ˆ
- ä¸è¦ç¼–é€ å·¥å…·ä¸å­˜åœ¨çš„åŠŸèƒ½
- ä¿æŒç®€æ´ï¼Œé¿å…å†—ä½™çš„å·¥å…·è°ƒç”¨
```

---

## äºŒã€å·¥å…·å®šä¹‰æç¤ºè¯æ¨¡æ¿

ä½ å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å·¥å…·æ¥å®Œæˆä»»åŠ¡ã€‚æ¯ä¸ªå·¥å…·éƒ½æœ‰ç‰¹å®šçš„åŠŸèƒ½å’Œå‚æ•°è¦æ±‚ã€‚

### 1. web_search
**åŠŸèƒ½**ï¼šåœ¨äº’è”ç½‘ä¸Šæœç´¢å®æ—¶ä¿¡æ¯
**ä½¿ç”¨åœºæ™¯**ï¼šéœ€è¦æœ€æ–°èµ„è®¯ã€å®æ—¶æ•°æ®ã€ä¸åœ¨è®­ç»ƒæ•°æ®ä¸­çš„ä¿¡æ¯
**å‚æ•°**ï¼š
- query (string, å¿…éœ€): æœç´¢å…³é”®è¯
- num_results (integer, å¯é€‰): è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ 5

**ç¤ºä¾‹**ï¼š
```json
{
  "tool": "web_search",
  "parameters": {
    "query": "2024å¹´ä¸Šæµ·å¤©æ°”é¢„æŠ¥",
    "num_results": 3
  }
}
```

### 2. code_executor
**åŠŸèƒ½**ï¼šæ‰§è¡Œ Python ä»£ç å¹¶è¿”å›ç»“æœ
**ä½¿ç”¨åœºæ™¯**ï¼šæ•°å­¦è®¡ç®—ã€æ•°æ®å¤„ç†ã€ç®—æ³•å®ç°
**å‚æ•°**ï¼š
- code (string, å¿…éœ€): è¦æ‰§è¡Œçš„ Python ä»£ç 
- timeout (integer, å¯é€‰): è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ 30

**ç¤ºä¾‹**ï¼š
```json
{
  "tool": "code_executor",
  "parameters": {
    "code": "import math\nresult = math.sqrt(144)\nprint(result)"
  }
}
```

### 3. memory_search
**åŠŸèƒ½**ï¼šä»é•¿æœŸè®°å¿†ä¸­æ£€ç´¢ç›¸å…³ä¿¡æ¯
**ä½¿ç”¨åœºæ™¯**ï¼šæŸ¥æ‰¾å†å²å¯¹è¯ã€ç”¨æˆ·åå¥½ã€è¿‡å¾€å†³ç­–
**å‚æ•°**ï¼š
- query (string, å¿…éœ€): æœç´¢æŸ¥è¯¢
- top_k (integer, å¯é€‰): è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤ 3

**ç¤ºä¾‹**ï¼š
```json
{
  "tool": "memory_search",
  "parameters": {
    "query": "ç”¨æˆ·çš„å’–å•¡åå¥½",
    "top_k": 3
  }
}
```

### 4. file_reader
**åŠŸèƒ½**ï¼šè¯»å–æ–‡ä»¶å†…å®¹
**ä½¿ç”¨åœºæ™¯**ï¼šåˆ†ææ–‡æ¡£ã€æå–ä¿¡æ¯
**å‚æ•°**ï¼š
- file_path (string, å¿…éœ€): æ–‡ä»¶è·¯å¾„
- encoding (string, å¯é€‰): æ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤ utf-8

### 5. memory_store
**åŠŸèƒ½**ï¼šå°†é‡è¦ä¿¡æ¯å­˜å‚¨åˆ°é•¿æœŸè®°å¿†
**ä½¿ç”¨åœºæ™¯**ï¼šä¿å­˜ç”¨æˆ·åå¥½ã€å…³é”®å†³ç­–ã€é‡è¦ä¿¡æ¯
**å‚æ•°**ï¼š
- content (string, å¿…éœ€): è¦å­˜å‚¨çš„å†…å®¹
- category (string, å¿…éœ€): åˆ†ç±»æ ‡ç­¾ï¼ˆå¦‚ "user_preference", "decision", "fact"ï¼‰

---

## å·¥å…·è°ƒç”¨åè®®

æ ¹æ®æ¥å…¥çš„æ¨¡å‹ä¸åŒï¼Œä½¿ç”¨å¯¹åº”çš„è°ƒç”¨æ ¼å¼ï¼š

### OpenAI / GLM-4 æ ¼å¼ï¼ˆFunction Callingï¼‰
æ¨¡å‹ä¼šè‡ªåŠ¨ç”Ÿæˆ tool_calls ç»“æ„ï¼Œä½ æ— éœ€æ‰‹åŠ¨æ„é€ 

### Anthropic Claude æ ¼å¼ï¼ˆTool Useï¼‰
æ¨¡å‹ä¼šè‡ªåŠ¨ç”Ÿæˆ tool_use å—ï¼Œä½ æ— éœ€æ‰‹åŠ¨æ„é€ 

### é€šç”¨æ ¼å¼ï¼ˆé€‚ç”¨äºä¸æ”¯æŒåŸç”Ÿå·¥å…·è°ƒç”¨çš„æ¨¡å‹ï¼‰
ä½¿ç”¨ JSON ä»£ç å—æ ‡è®°ï¼š

```tool_call
{
  "tool": "å·¥å…·åç§°",
  "parameters": {
    "å‚æ•°å": "å‚æ•°å€¼"
  }
}
```

ç³»ç»Ÿä¼šè§£æè¿™ä¸ª JSON å¹¶æ‰§è¡Œå¯¹åº”å·¥å…·ã€‚


## ä¸‰ã€å¤šæ¨¡å‹é€‚é…æ¶æ„ä»£ç 

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
import json
import re

# ============ ç»Ÿä¸€çš„æ¶ˆæ¯æ ¼å¼ ============
class Message:
    def __init__(self, role: str, content: str, 
                 tool_calls: Optional[List[Dict]] = None,
                 tool_call_id: Optional[str] = None):
        self.role = role  # system/user/assistant/tool
        self.content = content
        self.tool_calls = tool_calls
        self.tool_call_id = tool_call_id

# ============ æŠ½è±¡ LLM æ¥å£ ============
class LLMProvider(ABC):
    """ç»Ÿä¸€çš„ LLM æä¾›å•†æ¥å£"""
    
    @abstractmethod
    def chat(self, messages: List[Message], 
             tools: Optional[List[Dict]] = None,
             **kwargs) -> Message:
        """å‘é€å¯¹è¯è¯·æ±‚"""
        pass
    
    @abstractmethod
    def format_tools(self, tools: List[Dict]) -> Any:
        """å°†å·¥å…·å®šä¹‰è½¬æ¢ä¸ºè¯¥æ¨¡å‹çš„æ ¼å¼"""
        pass
    
    @abstractmethod
    def parse_response(self, response: Any) -> Message:
        """è§£ææ¨¡å‹å“åº”ä¸ºç»Ÿä¸€æ ¼å¼"""
        pass


# ============ OpenAI é€‚é…å™¨ ============
class OpenAIProvider(LLMProvider):
    def __init__(self, api_key: str, model: str = "gpt-4-turbo",
                 base_url: Optional[str] = None):
        from openai import OpenAI
        self.client = OpenAI(api_key=api_key, base_url=base_url)
        self.model = model
    
    def chat(self, messages: List[Message], 
             tools: Optional[List[Dict]] = None,
             **kwargs) -> Message:
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        openai_messages = self._convert_messages(messages)
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        params = {
            "model": self.model,
            "messages": openai_messages,
            **kwargs
        }
        
        if tools:
            params["tools"] = self.format_tools(tools)
            params["tool_choice"] = "auto"
        
        # è°ƒç”¨ API
        response = self.client.chat.completions.create(**params)
        return self.parse_response(response)
    
    def format_tools(self, tools: List[Dict]) -> List[Dict]:
        """OpenAI Function Calling æ ¼å¼"""
        return [{
            "type": "function",
            "function": {
                "name": tool["name"],
                "description": tool["description"],
                "parameters": tool["parameters"]
            }
        } for tool in tools]
    
    def parse_response(self, response) -> Message:
        message = response.choices[0].message
        
        tool_calls = None
        if hasattr(message, 'tool_calls') and message.tool_calls:
            tool_calls = [{
                "id": tc.id,
                "name": tc.function.name,
                "arguments": json.loads(tc.function.arguments)
            } for tc in message.tool_calls]
        
        return Message(
            role="assistant",
            content=message.content or "",
            tool_calls=tool_calls
        )
    
    def _convert_messages(self, messages: List[Message]) -> List[Dict]:
        result = []
        for msg in messages:
            openai_msg = {"role": msg.role, "content": msg.content}
            
            if msg.tool_calls:
                openai_msg["tool_calls"] = [{
                    "id": tc["id"],
                    "type": "function",
                    "function": {
                        "name": tc["name"],
                        "arguments": json.dumps(tc["arguments"], ensure_ascii=False)
                    }
                } for tc in msg.tool_calls]
            
            if msg.tool_call_id:
                openai_msg["tool_call_id"] = msg.tool_call_id
            
            result.append(openai_msg)
        return result


# ============ Anthropic é€‚é…å™¨ ============
class AnthropicProvider(LLMProvider):
    def __init__(self, api_key: str, model: str = "claude-3-5-sonnet-20241022"):
        from anthropic import Anthropic
        self.client = Anthropic(api_key=api_key)
        self.model = model
    
    def chat(self, messages: List[Message], 
             tools: Optional[List[Dict]] = None,
             **kwargs) -> Message:
        # æå– system æ¶ˆæ¯
        system_msg = None
        user_messages = []
        
        for msg in messages:
            if msg.role == "system":
                system_msg = msg.content
            else:
                user_messages.append(msg)
        
        # è½¬æ¢æ¶ˆæ¯æ ¼å¼
        anthropic_messages = self._convert_messages(user_messages)
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        params = {
            "model": self.model,
            "max_tokens": kwargs.get("max_tokens", 4096),
            "messages": anthropic_messages
        }
        
        if system_msg:
            params["system"] = system_msg
        
        if tools:
            params["tools"] = self.format_tools(tools)
        
        # è°ƒç”¨ API
        response = self.client.messages.create(**params)
        return self.parse_response(response)
    
    def format_tools(self, tools: List[Dict]) -> List[Dict]:
        """Anthropic Tool Use æ ¼å¼"""
        return [{
            "name": tool["name"],
            "description": tool["description"],
            "input_schema": tool["parameters"]
        } for tool in tools]
    
    def parse_response(self, response) -> Message:
        content_text = ""
        tool_calls = []
        
        for block in response.content:
            if block.type == "text":
                content_text += block.text
            elif block.type == "tool_use":
                tool_calls.append({
                    "id": block.id,
                    "name": block.name,
                    "arguments": block.input
                })
        
        return Message(
            role="assistant",
            content=content_text,
            tool_calls=tool_calls if tool_calls else None
        )
    
    def _convert_messages(self, messages: List[Message]) -> List[Dict]:
        result = []
        for msg in messages:
            if msg.role == "tool":
                # Anthropic çš„å·¥å…·ç»“æœæ ¼å¼
                result.append({
                    "role": "user",
                    "content": [{
                        "type": "tool_result",
                        "tool_use_id": msg.tool_call_id,
                        "content": msg.content
                    }]
                })
            elif msg.tool_calls:
                # æœ‰å·¥å…·è°ƒç”¨çš„ assistant æ¶ˆæ¯
                content_blocks = []
                if msg.content:
                    content_blocks.append({
                        "type": "text",
                        "text": msg.content
                    })
                for tc in msg.tool_calls:
                    content_blocks.append({
                        "type": "tool_use",
                        "id": tc["id"],
                        "name": tc["name"],
                        "input": tc["arguments"]
                    })
                result.append({
                    "role": "assistant",
                    "content": content_blocks
                })
            else:
                result.append({
                    "role": msg.role,
                    "content": msg.content
                })
        return result


# ============ é€šç”¨é€‚é…å™¨ï¼ˆæ”¯æŒ GLM/Kimi ç­‰å…¼å®¹ OpenAI çš„æ¨¡å‹ï¼‰============
class CompatibleProvider(OpenAIProvider):
    """
    å…¼å®¹ OpenAI SDK çš„æ¨¡å‹æä¾›å•†
    é€‚ç”¨äºï¼šGLM-4, Kimi, DeepSeek ç­‰
    """
    def __init__(self, api_key: str, model: str, base_url: str):
        super().__init__(api_key, model, base_url)
        self.supports_native_tools = self._check_tool_support()
    
    def _check_tool_support(self) -> bool:
        """æ£€æµ‹æ¨¡å‹æ˜¯å¦æ”¯æŒåŸç”Ÿå·¥å…·è°ƒç”¨"""
        # è¿™é‡Œå¯ä»¥ç»´æŠ¤ä¸€ä¸ªæ”¯æŒåˆ—è¡¨
        native_support_models = [
            "glm-4",
            "glm-4-plus", 
            "moonshot-v1"  # Kimi
        ]
        return any(m in self.model.lower() for m in native_support_models)
    
    def chat(self, messages: List[Message], 
             tools: Optional[List[Dict]] = None,
             **kwargs) -> Message:
        if not self.supports_native_tools and tools:
            # é™çº§åˆ°æ–‡æœ¬æ¨¡å¼å·¥å…·è°ƒç”¨
            return self._chat_with_text_tools(messages, tools, **kwargs)
        else:
            return super().chat(messages, tools, **kwargs)
    
    def _chat_with_text_tools(self, messages: List[Message],
                              tools: List[Dict], **kwargs) -> Message:
        """ä½¿ç”¨æ–‡æœ¬æ ¼å¼çš„å·¥å…·è°ƒç”¨ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        # å°†å·¥å…·å®šä¹‰æ·»åŠ åˆ° system prompt
        tool_descriptions = self._format_tools_as_text(tools)
        
        # ä¿®æ”¹æ¶ˆæ¯
        enhanced_messages = messages.copy()
        for msg in enhanced_messages:
            if msg.role == "system":
                msg.content += f"\n\n{tool_descriptions}"
                break
        else:
            enhanced_messages.insert(0, Message(
                role="system",
                content=tool_descriptions
            ))
        
        # è°ƒç”¨æ¨¡å‹
        response = super().chat(enhanced_messages, tools=None, **kwargs)
        
        # è§£ææ–‡æœ¬ä¸­çš„å·¥å…·è°ƒç”¨
        parsed = self._parse_text_tool_calls(response.content)
        if parsed:
            response.tool_calls = parsed
        
        return response
    
    def _format_tools_as_text(self, tools: List[Dict]) -> str:
        """å°†å·¥å…·å®šä¹‰æ ¼å¼åŒ–ä¸ºæ–‡æœ¬"""
        text = "# å¯ç”¨å·¥å…·\n\n"
        for tool in tools:
            text += f"## {tool['name']}\n"
            text += f"{tool['description']}\n\n"
            text += "å‚æ•°ï¼š\n```json\n"
            text += json.dumps(tool['parameters'], indent=2, ensure_ascii=False)
            text += "\n```\n\n"
        
        text += """
ä½¿ç”¨å·¥å…·æ—¶ï¼Œè¯·ä½¿ç”¨ä»¥ä¸‹æ ¼å¼ï¼š
```tool_call
{
  "tool": "å·¥å…·åç§°",
  "parameters": {å‚æ•°å¯¹è±¡}
}
"""
        return text
    
    def _parse_text_tool_calls(self, content: str) -> Optional[List[Dict]]:
        """ä»æ–‡æœ¬ä¸­è§£æå·¥å…·è°ƒç”¨"""
        pattern = r'```tool_call\s*\n(.*?)\n```'
        matches = re.findall(pattern, content, re.DOTALL)
        
        if not matches:
            return None
        
        tool_calls = []
        for match in matches:
            try:
                call_data = json.loads(match)
                tool_calls.append({
                    "id": f"call_{len(tool_calls)}",
                    "name": call_data["tool"],
                    "arguments": call_data["parameters"]
                })
            except json.JSONDecodeError:
                continue
        
        return tool_calls if tool_calls else None


# ============ å·¥å…·ç®¡ç†å™¨ ============
class Tool:
    def __init__(self, name: str, description: str,
                 parameters: Dict, func: callable):
        self.name = name
        self.description = description
        self.parameters = parameters
        self.func = func
    
    def execute(self, **kwargs) -> str:
        try:
            result = self.func(**kwargs)
            return str(result)
        except Exception as e:
            return f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(e)}"
    
    def to_dict(self) -> Dict:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": self.parameters
        }


# ============ Agent æ ¸å¿ƒ ============
class Agent:
    def __init__(self, llm_provider: LLMProvider, 
                 tools: List[Tool],
                 system_prompt: str):
        self.llm = llm_provider
        self.tools = {t.name: t for t in tools}
        self.system_prompt = system_prompt
        self.messages: List[Message] = []
        
        # åˆå§‹åŒ–ç³»ç»Ÿæ¶ˆæ¯
        self.messages.append(Message(
            role="system",
            content=system_prompt
        ))
    
    def run(self, user_input: str, max_iterations: int = 5) -> str:
        """æ‰§è¡Œ Agent ä¸»å¾ªç¯"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
        self.messages.append(Message(
            role="user",
            content=user_input
        ))
        
        for iteration in range(max_iterations):
            print(f"\n{'='*50}")
            print(f"è¿­ä»£ {iteration + 1}/{max_iterations}")
            print(f"{'='*50}")
            
            # è°ƒç”¨ LLM
            response = self.llm.chat(
                messages=self.messages,
                tools=[t.to_dict() for t in self.tools.values()]
            )
            
            self.messages.append(response)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
            if response.tool_calls:
                print(f"\nğŸ”§ æ£€æµ‹åˆ° {len(response.tool_calls)} ä¸ªå·¥å…·è°ƒç”¨")
                
                # æ‰§è¡Œæ‰€æœ‰å·¥å…·
                for tool_call in response.tool_calls:
                    tool_name = tool_call["name"]
                    tool_args = tool_call["arguments"]
                    
                    print(f"\næ‰§è¡Œå·¥å…·: {tool_name}")
                    print(f"å‚æ•°: {json.dumps(tool_args, ensure_ascii=False)}")
                    
                    # æ‰§è¡Œå·¥å…·
                    if tool_name in self.tools:
                        result = self.tools[tool_name].execute(**tool_args)
                    else:
                        result = f"é”™è¯¯ï¼šå·¥å…· '{tool_name}' ä¸å­˜åœ¨"
                    
                    print(f"ç»“æœ: {result[:200]}...")
                    
                    # æ·»åŠ å·¥å…·ç»“æœæ¶ˆæ¯
                    self.messages.append(Message(
                        role="tool",
                        content=result,
                        tool_call_id=tool_call["id"]
                    ))
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œè¿”å›æœ€ç»ˆç­”æ¡ˆ
                print(f"\nâœ“ Agent å®Œæˆä»»åŠ¡")
                return response.content
        
        return "è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œä»»åŠ¡æœªå®Œæˆ"
    
    def reset(self):
        """é‡ç½®å¯¹è¯å†å²"""
        self.messages = [Message(
            role="system",
            content=self.system_prompt
        )]


# ============ ä½¿ç”¨ç¤ºä¾‹ ============
if __name__ == "__main__":
    # å®šä¹‰å·¥å…·
    def search_web(query: str) -> str:
        return f"æœç´¢ç»“æœï¼šå…³äº'{query}'çš„æœ€æ–°ä¿¡æ¯..."
    
    def calculate(expression: str) -> str:
        try:
            result = eval(expression)
            return f"è®¡ç®—ç»“æœ: {result}"
        except Exception as e:
            return f"è®¡ç®—é”™è¯¯: {str(e)}"
    
    tools = [
        Tool(
            name="web_search",
            description="åœ¨äº’è”ç½‘ä¸Šæœç´¢å®æ—¶ä¿¡æ¯",
            parameters={
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢å…³é”®è¯"
                    }
                },
                "required": ["query"]
            },
            func=search_web
        ),
        Tool(
            name="calculator",
            description="æ‰§è¡Œæ•°å­¦è®¡ç®—",
            parameters={
                "type": "object",
                "properties": {
                    "expression": {
                        "type": "string",
                        "description": "æ•°å­¦è¡¨è¾¾å¼ï¼Œå¦‚ '2+2' æˆ– 'math.sqrt(16)'"
                    }
                },
                "required": ["expression"]
            },
            func=calculate
        )
    ]
    
    # ç³»ç»Ÿæç¤ºè¯ï¼ˆä½¿ç”¨å‰é¢è®¾è®¡çš„ï¼‰
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªè‡ªä¸»çš„ AI Agentï¼Œèƒ½å¤Ÿé€šè¿‡å·¥å…·è°ƒç”¨æ¥å®Œæˆå¤æ‚ä»»åŠ¡ã€‚

å·¥ä½œæµç¨‹ï¼š
1. ç†è§£ç”¨æˆ·éœ€æ±‚
2. åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·ï¼ˆèƒ½ç›´æ¥å›ç­”å°±ä¸è°ƒç”¨ï¼‰
3. è°ƒç”¨å¿…è¦çš„å·¥å…·
4. ç»¼åˆä¿¡æ¯ç»™å‡ºç­”æ¡ˆ

æ³¨æ„ï¼š
- å…ˆæ€è€ƒå†è¡ŒåŠ¨
- ä¸€æ¬¡åªè°ƒç”¨å¿…è¦çš„å·¥å…·
- åŸºäºå·¥å…·ç»“æœå›ç­”ï¼Œä¸è¦ç¼–é€ ä¿¡æ¯
"""
    
    # ========== ç¤ºä¾‹ 1: ä½¿ç”¨ OpenAI ==========
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 1: OpenAI GPT-4")
    print("="*60)
    
    openai_provider = OpenAIProvider(
        api_key="your-openai-key",
        model="gpt-4-turbo"
    )
    agent1 = Agent(openai_provider, tools, system_prompt)
    result1 = agent1.run("å¸®æˆ‘æœç´¢ä»Šå¤©çš„å¤©æ°”ï¼Œç„¶åè®¡ç®— 25 * 4")
    print(f"\næœ€ç»ˆç­”æ¡ˆ:\n{result1}")
    
    
    # ========== ç¤ºä¾‹ 2: ä½¿ç”¨ Anthropic Claude ==========
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 2: Anthropic Claude")
    print("="*60)
    
    anthropic_provider = AnthropicProvider(
        api_key="your-anthropic-key",
        model="claude-3-5-sonnet-20241022"
    )
    agent2 = Agent(anthropic_provider, tools, system_prompt)
    result2 = agent2.run("è®¡ç®— 100 çš„å¹³æ–¹æ ¹")
    print(f"\næœ€ç»ˆç­”æ¡ˆ:\n{result2}")
    
    
    # ========== ç¤ºä¾‹ 3: ä½¿ç”¨ GLM-4ï¼ˆæ™ºè°± AIï¼‰==========
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 3: GLM-4")
    print("="*60)
    
    glm_provider = CompatibleProvider(
        api_key="your-glm-key",
        model="glm-4-plus",
        base_url="https://open.bigmodel.cn/api/paas/v4"
    )
    agent3 = Agent(glm_provider, tools, system_prompt)
    result3 = agent3.run("æœç´¢ Python æœ€æ–°ç‰ˆæœ¬")
    print(f"\næœ€ç»ˆç­”æ¡ˆ:\n{result3}")
    
    
    # ========== ç¤ºä¾‹ 4: ä½¿ç”¨ Kimiï¼ˆæœˆä¹‹æš—é¢ï¼‰==========
    print("\n" + "="*60)
    print("ç¤ºä¾‹ 4: Kimi")
    print("="*60)
    
    kimi_provider = CompatibleProvider(
        api_key="your-kimi-key",
        model="moonshot-v1-32k",
        base_url="https://api.moonshot.cn/v1"
    )
    agent4 = Agent(kimi_provider, tools, system_prompt)
    result4 = agent4.run("å¸®æˆ‘è®¡ç®— 15% çš„ç¨åæ˜¯å¤šå°‘ï¼Œå‡è®¾åŸä»· 200 å…ƒ")
    print(f"\næœ€ç»ˆç­”æ¡ˆ:\n{result4}")
```

---

## å››ã€é…ç½®æ–‡ä»¶ç¤ºä¾‹

```yaml
# config.yaml
models:
  openai:
    api_key: "sk-xxx"
    model: "gpt-4-turbo"
    base_url: null
  
  anthropic:
    api_key: "sk-ant-xxx"
    model: "claude-3-5-sonnet-20241022"
  
  glm:
    api_key: "xxx.xxx"
    model: "glm-4.7"
    base_url: "https://open.bigmodel.cn/api/paas/v4"
  
  kimi:
    api_key: "sk-xxx"
    model: "moonshot-v1-32k"
    base_url: "https://api.moonshot.cn/v1"
  
  deepseek:
    api_key: "sk-xxx"
    model: "deepseek-chat"
    base_url: "https://api.deepseek.com"

agent:
  max_iterations: 5
  temperature: 0.7
  timeout: 30
```

---

## äº”ã€ä½¿ç”¨å·¥å‚æ¨¡å¼åˆ›å»º Provider

```python
import yaml
from typing import Dict

class LLMFactory:
    @staticmethod
    def create(provider_name: str, config: Dict) -> LLMProvider:
        """æ ¹æ®é…ç½®åˆ›å»º LLM Provider"""
        
        if provider_name == "openai":
            return OpenAIProvider(
                api_key=config["api_key"],
                model=config["model"],
                base_url=config.get("base_url")
            )
        
        elif provider_name == "anthropic":
            return AnthropicProvider(
                api_key=config["api_key"],
                model=config["model"]
            )
        
        elif provider_name in ["glm", "kimi", "deepseek"]:
            return CompatibleProvider(
                api_key=config["api_key"],
                model=config["model"],
                base_url=config["base_url"]
            )
        
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„ provider: {provider_name}")

# ä½¿ç”¨ç¤ºä¾‹
with open("config.yaml") as f:
    config = yaml.safe_load(f)

# åŠ¨æ€åˆ‡æ¢æ¨¡å‹
provider = LLMFactory.create("glm", config["models"]["glm"])
agent = Agent(provider, tools, system_prompt)
```

---

## å…­ã€å…³é”®è®¾è®¡è¦ç‚¹æ€»ç»“

### âœ… **ç»Ÿä¸€æŠ½è±¡å±‚**
- æ‰€æœ‰æ¨¡å‹é€šè¿‡ `LLMProvider` æ¥å£è®¿é—®
- æ¶ˆæ¯æ ¼å¼ç»Ÿä¸€ä¸º `Message` ç±»
- å·¥å…·å®šä¹‰ç»Ÿä¸€ä¸ºæ ‡å‡† JSON Schema

### âœ… **é™çº§ç­–ç•¥**
- åŸç”Ÿæ”¯æŒå·¥å…·è°ƒç”¨ â†’ ç›´æ¥ä½¿ç”¨
- ä¸æ”¯æŒ â†’ é™çº§åˆ°æ–‡æœ¬æ ¼å¼å·¥å…·è°ƒç”¨

### âœ… **æç¤ºè¯åˆ†å±‚**
1. **ç³»ç»Ÿå±‚**ï¼šå®šä¹‰ Agent èº«ä»½å’Œå·¥ä½œæµç¨‹
2. **å·¥å…·å±‚**ï¼šåŠ¨æ€æ³¨å…¥å¯ç”¨å·¥å…·åˆ—è¡¨
3. **ä»»åŠ¡å±‚**ï¼šç”¨æˆ·å…·ä½“è¯·æ±‚

### âœ… **å¯æ‰©å±•æ€§**
- æ–°å¢æ¨¡å‹ï¼šç»§æ‰¿ `LLMProvider` å®ç°é€‚é…å™¨
- æ–°å¢å·¥å…·ï¼šåˆ›å»º `Tool` å®ä¾‹å¹¶æ³¨å†Œ
- æ–°å¢åŠŸèƒ½ï¼šåœ¨ `Agent` ç±»ä¸­æ‰©å±•

